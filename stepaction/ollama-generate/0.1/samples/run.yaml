apiVersion: tekton.dev/v1
kind: TaskRun
metadata:
  generateName: ollama-generate-sample-
spec:
  taskSpec:
    workspaces:
      - name: ollama-cache
    sidecars:
      - name: ollama-server
        image: docker.io/ollama/ollama:latest
        env:
          - name: OLLAMA_HOST
            value: "0.0.0.0:11434"
        volumeMounts:
          - name: $(workspaces.ollama-cache.volume)
            mountPath: /root/.ollama
        readinessProbe:
          httpGet:
            path: /
            port: 11434
    steps:
      - name: pull
        ref:
          name: ollama-pull
        params:
          - name: model
            value: tinyllama
      - name: generate
        ref:
          name: ollama-generate
        params:
          - name: model
            value: tinyllama
          - name: prompt
            value: "Say hello!"
  workspaces:
    - name: ollama-cache
      emptyDir: {}
